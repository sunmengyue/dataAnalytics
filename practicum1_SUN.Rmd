---
title: "Practicum1_SUN"
author: "Mengyue Sun"
date: "10/7/2018"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problem 1
1.  Download the data set Glass Identification Database along with its explanation. 
```{r}
glass <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/glass.data.csv", header = FALSE, sep = ",")
names(glass) <- c("Id", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe", "glassType")
# Add column names to the dataset
```

2.Explore the data set as you see fit and that allows you to get a sense of the data and get comfortable with it.
```{r}
str(glass)
# transform the glassType into factor.First we take a look at what types are there 
unique(glass$glassType)
glass$glassType <- factor(glass$glassType, 
                     labels = c("buildingFloat", "buildingNonFloat",
                                "vehicleFloat", "containers", "tableware", "headlamps"))
class(glass$glassType)
summary(glass[, 3:10])
```

3.Create a histogram of the Na column and overlay a normal curve; visually determine whether the data is normally distributed. Does the k-NN algorithm require normally distributed data or is it a non-parametric method?
```{r}
NaData <- glass$Na
h <- hist(NaData, col = "red", xlab = "Na: Sodium", main="Histogram with Normal Curve")
xfit<-seq(min(NaData),max(NaData),length=40) 
yfit<-dnorm(xfit,mean=mean(NaData),sd=sd(NaData)) 
yfit <- yfit*diff(h$mids[1:2])*length(NaData) 
lines(xfit, yfit, col="blue", lwd=2)
```
The histogram presents to be normally distributed.It shows that the mean, median, and mode are around 13.5. The k-NN algorithm does not require normally distributed data and it is a non-parametric method. 

4.After removing the ID column (column 1), normalize the first two columns in the data set using min-max normalization.
```{r }
#remove the first column and assign the data to glass2
glass2 <- glass[, -1]

#create a function called normalize
normalize <- function(x) {
   return( (x - min(x)) / ( max(x) - min(x) ) )
}

#normalize the first 2 columns and save them to glass2
glassSub <- as.data.frame(lapply(glass2[, c(1:2)], normalize))
head(glassSub)
summary(glassSub)
glass2[, 1:2] <- glassSub
```

5.Normalize the remaining columns, except the last one, using z-score standardization
```{r }
#create a function named normalizeZ
normalizeZ <- function(x){
  return( (x - mean(x)) / sd(x) )
}

#normalize the remaining columns and save them to glass2
glassSub2 <- as.data.frame(lapply(glass2[, c(3:9)], normalizeZ))
head(glassSub2)
summary(glassSub2)
glass2[, 3:9] <- glassSub2
summary(glass2)
```

6. The data set is sorted, so creating a validation data set requires random selection of elements. Create a stratified sample where you randomly select 50% of each of the cases for each glass type to be part of the validation data set. The remaining cases will form the training data set
```{r }
#Create a dataset in random selection order
set.seed(123)
gp <- runif(nrow(glass2))
glass2 <- glass2[order(gp), ]
head(glass2, 15)
str(glass2)

#Data partitioning
glass2Train <- glass2[1 : 107, ]
glass2Test <- glass2[108 : 214, ]
```

7.Implement the k-NN algorithm in R (do not use an implementation of k-NN from a package) and use your algorithm with a k=10 to predict the glass type for the following two cases:. Use the whole normalized data set for this; not just the training data set. Note that you need to normalize the values of the new cases the same way as you normalized the original data.
```{r }
unknownGlass1 <- c(1.51621, 12.53, 3.48, 1.39, 73.39, 0.60, 8.55, 0.00, 0.05)
unknownGlass2 <- c(1.5098, 12.77, 1.85, 1.81, 72.69, 0.59, 10.01, 0.00, 0.01)

#A. transform the given data
#a. binding the new data into the original data
glass3 <- rbind(unknownGlass1, glass)
glass3 <- rbind(unknownGlass2, glass3)
glass3 <- glass3[, -1]

#transfrom the first 2 column using min-max normalization
glass3Sub <- as.data.frame(lapply(glass3[, c(1:2)], normalize))
head(glass3Sub)
summary(glass3Sub)
glass3[, 1:2] <- glass3Sub

#transform the left using Z score standarzation
#normalize the remaining columns and save them to glass2
glass3Sub2 <- as.data.frame(lapply(glass3[, c(3:9)], normalizeZ))
head(glass3Sub2)
summary(glassSub2)
glass3[, 3:9] <- glass3Sub2
summary(glass3)

#take out the 2 unknow cases from glass3

unknownGlass1Tran <- glass3[1, ]
unknownGlass2Tran <- glass3[2, ]
unknownGlass1Tran
unknownGlass2Tran
glass3 <- glass3[-c(1, 2), ]

#B. Predict the glass type for the unkonwn glasses
#for 2 single cases:
getDist <- function(p, q) {
  dsq <- 0
  for (i in 1 : length(p)) {
    dsq <- dsq + (p[i] - q[i])^2
  }
   return(sqrt(dsq))
}

#For the first unknown glass:
#loop through each row in the glass3 data set 
getDistN <- function(training, q) {
  distance <- numeric(nrow(training))
  q <- as.numeric(unknownGlass1Tran[c(1:9)])
  for (i in 1 : nrow(training)) {
    p <- training[i, c(1:9)]
    distance[i] <- getDist(p, q)
  }
  return(distance) 
} 

n1 <- getDistN(glass3, unknownGlass1Tran)

#getting the k closest neighbors in for unknownGlass1Tran
findKClosest <- function(neighbors, k) {
  neighborOrder <- order(neighbors)
   return (neighborOrder[1 : k])
}
f <- findKClosest(n1, 10)

vote <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
vote(glass3$glassType[f])
# We know that the first unknown glass could be containers

#For the second unknown glass:
getDistN2 <- function(training, q) {
  distance <- numeric(nrow(training))
  q <- as.numeric(unknownGlass2Tran[c(1:9)])
  for (i in 1 : nrow(training)) {
    p <- training[i, c(1:9)]
    distance[i] <- getDist(p, q)
  }
  return(distance) 
}

n2 <- getDistN2(glass3, unknownGlass2Tran)

#getting the k closest neighbors in for unknownGlass2Tran
f2 <- findKClosest(n2, 10)
vote(glass3$glassType[f2])
# The second unknown glass could also be containers
```

8. Apply the knn function from the class package with k=14 and redo the cases from Question (7).
```{r }
library(class)
unknownType1 <- knn(train = glass3[, -10], test = unknownGlass1Tran[-10 ], cl = glass3$glassType, k = 14 )
unknownType1
unknownType2 <- knn(train = glass3[, -10], test = unknownGlass2Tran[-10 ], cl = glass3$glassType, k = 14 )
unknownType2
# The class package predicts both of the unknown glasses are building_windows_non_float_processed
```

9. Determine the accuracy of the knn function with k=14 from the class package by applying it against each case in the validation data set. What is the percentage of correct classifications?
```{r }
library(class)
glass2TrainTarget <- glass2[1 : 107, 10]
glass2TestTarget <- glass2[108 : 214, 10]

d <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 14)
table(glass2TestTarget, d)
accuracy14 <- (26 + 29 + 10) / 107
accuracy14
```
The percentage of correct classification is:
(27 + 28 + 10) / 107 = 60.75%

10. Determine an optimal k by trying all values from 5 through 14 for your own k-NN algorithm implementation against the cases in the validation data set. What is the optimal k, i.e., the k that results in the best accuracy? Plot k versus accuracy.
```{r}
# when k = 5
d5 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 5)
table(glass2TestTarget, d5)
# accruacy5 = (24 + 23 + 3 + 11 + 1) / 107 = 57.94%

# when k = 6
d6 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 6)
table(glass2TestTarget, d6)
#accruacy6 = (26 + 21 + 1 + 4 + 10) / 107 = 57.94%

d7 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 7)
table(glass2TestTarget, d7)
#accuracy7 = (23 + 25 + 3 + 10) / 107 = 57.01%

d8 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 8)
table(glass2TestTarget, d8)
# accuracy8 = (26 + 25 + 3 + 10) / 107 = 59.81%

d9 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 9)
table(glass2TestTarget, d9)
#accuracy9 = (25 + 25 + 1 + 10)/107 = 57.01%

d10 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 10)
table(glass2TestTarget, d10)
#accuracy10 = (22 + 25 + 3 + 10) / 107 = 56.07%

d11 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 11)
table(glass2TestTarget, d11)
#accuracy11 = (23 + 28 + 2 + 10) / 107 = 58.87%

d12 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 12)
table(glass2TestTarget, d12)
#accuracy12 = (25 + 28 + 2 + 10)/107 = 60.75%

d13 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 13)
table(glass2TestTarget, d13)
#accuracy13 = (27 + 26 + 1 + 10) / 107 = 59.81%, and from q9 we know accuracy14 = 60.75%

k <- c(5, 6, 7, 8, 9, 10, 11, 12, 13, 14)
accuracy <- c(0.5794,  0.5794, 0.5700, 0.5981, 0.5701, 0.5607, 0.5888, 0.6075, 0.5981, 0.6074766)
accuracyChange <- data.frame(cbind(k, accuracy))
library(ggplot2)
ggplot(accuracyChange, aes(x = k, y = accuracy)) + geom_line()
```

11. Create a plot of k (x-axis) versus error rate (percentage of incorrect classifications) using ggplot.
```{r }
error <- c(0.4206, 0.4206, 0.4300, 0.40191, 0.4299, 0.4393, 0.4112, 0.3943, 0.4019, 0.3925)
errorChange <- data.frame(cbind(k, error))
ggplot(errorChange, aes(x = k, y = error)) + geom_line()

```

12. Produce a cross-table confusion matrix showing the accuracy of the classification using a package of your choice and a k of your choice.
```{r }
#when k = 12: 
library("gmodels")
testPred <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 12)
CrossTable(x = glass2TestTarget, y = testPred, prop.chisq=FALSE)
```

13. Comment on the run-time complexity of the k-NN for classifying w new cases using a training data set of n cases having m features. Assume that m is "large". How does this algorithm behave as w, n, and m increase? Would this algorithm be "fast" if the training data set and the number of features are large?

The algorithms will get slower and slower as the 2, n, and m increases becasue there are more inputs which take more time to process. 

# Problem 2
1.Investigate this data set of home prices in King County (USA).
```{r }
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
str(homeprice)

# We know that there are 21613 cases, 21 features. 

#To use knn to predict the home price, I will break down the home price in to several range and transfer the variable to factor
summary(homeprice$price)
homePrice2 <- within(homeprice, {
  price[price < 100000] <- "< 100000"
  price[price >= 100000 & price < 600000 ] <- "100000-59999"
  price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
  price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
  price[price >= 1600000] <- ">1600000"
})
homePrice2$price <- factor(homePrice2$price, 
                           levels = c("< 100000", "100000-59999","600000-1099999", "1100000-1599999", ">1600000"))
str(homePrice2$price)
summary(homePrice2)
anyNA(homePrice2)
homePrice2 <- na.omit(homePrice2)
str(homePrice2)
#normalize the dataset
homePriceSub <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
homePrice3 <- data.frame(cbind(homePrice2[, 2:3]), homePriceSub) #exclude the id column
str(homePrice3)

#data partition
set.seed(9850)
gp <- runif(nrow(homePrice3))
homePrice3 <- homePrice3[order(gp), ]
head(homePrice3, 15)
str(homePrice3)
nrow(homePrice3)

priceTrain <- homePrice3[1 : 14944, ] #70% of the data are set as training
priceTest <- homePrice3[14945 : 21349, ]
priceTrainTarget <- priceTrain$price
priceTestTarget <- priceTest$price

sqrt(nrow(homePrice3))
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147)
table(priceTestTarget, predTest)
```
2. How would you evaluate the model? While you need to only describe how to evaluate the model, you may calculate an actual metric.
```{r }
nrow(predTest)
AccuracyRate <-  (4784 + 431) / 6405
AccuracyRate
#The model has a good accuracy rate at 81.42%
```

# Problem 3
13. Inspect the data set of occupancy rates for a series of time periods. Which forecasting method is most appropriate to use for forecast the next time period? Calculate a forecast for the next time period with a 95% prediction interval. Comment on the bias of your forecasting model
``` {r }
Occupancy <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/occupancyratestimeseries (1).csv")

ggplot(Occupancy, aes(x = Period, y = OccupancyRate)) + geom_line()
# Because ther change is drastic, weighted moving average is not a good fit. We can see there is a general patter in the graph. So we will try exponential smoothing and linear regression which use all of the data point to predic the occupancy rate at the next time period.
#Exponential Smoothing
#alpha = 0.3
Occupancy$Ft = 0
Occupancy$E = 0
head(Occupancy)
Occupancy$Ft[1] <- Occupancy[1, 2]
head(Occupancy)

#Ft = F(t - 1) + a * E(t - 1)
for (i in 2:nrow(Occupancy)) {
  Occupancy$Ft[i] <- Occupancy$Ft[i - 1] + 0.3 * Occupancy$E[i - 1]
  Occupancy$E[i] <- Occupancy[i, 2] - Occupancy$Ft[i]
}

n <- nrow(Occupancy)
Forcast <- Occupancy$Ft[n] + 0.3 * Occupancy$E[n]
Forcast

#linear regression
nrow(Occupancy)
model <- lm(Occupancy$OccupancyRate ~ Occupancy$Period)
summary(model)
F167 <- 34.94191 + 0.01510  * 167
F167 

#MSE for Exponential Smoothing
library(tidyverse)
Occupancy <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
ES_MSE <- mean(Occupancy$sqErr)
ES_MSE

#MSE for linear regression
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
lr_MSE <- mean(Occupancy2$sqErr)
lr_MSE

#Because the linear regression method has a smaller mean squared error, the linear regression is better.
# 95% confidence interval is yt±1.96σ
mySD <- sd(Occupancy$OccupancyRate)
mySD
#next time period with a 95% prediction interval
OccupanyRatext1 <- F167 + 1.96 * mySD
OccupanyRateNext2 <- F167 - 1.96 * mySD
OccupanyRatext1
OccupanyRateNext2
# The next time period with a 95% prediction interval is 23.02 to 51.90
```

