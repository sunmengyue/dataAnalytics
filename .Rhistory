install.packages("gmodels")
library("gmodels")
CrossTable(x = glass2TestTarget, y = testPred, prop.chisq=FALSE)
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
View(homeprice)
nrow(homeprice)
str(homeprice)
str(homeprice)
x1 <- c(rnorm(20, mean=1), rnorm(20, mean=5))
x2 <- c(rnorm(20, mean=5), rnorm(20, mean=1))
y=rep(1:2,each=20)
x <- cbind(x1,x2)
x
y
train <- sample(1:40, 30)
train
plot(x1[train], x2[train], col=y[train]+1)
plot(x1[train], x2[train], col=y[train]+1)
test <- (1:40)[-train]
test
kdist <- knn.dist(x)
kdist
preds <- knn.predict(train, test, y ,kdist, k=3, agg.meth="majority")
library(class)
library(dplyr)
library(lubridate)
set.seed(100)
Occupancy <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/occupancyratestimeseries (1).csv")
View(Occupancy)
Occupancy$Ft = 0
Occupancy$E = 0
View(Occupancy)
head(Occupancy)
Occupancy$Ft[1] <- Occupancy[1, 2]
head(Occupancy)
View(Occupancy)
for (i in 2:nrow(Occupancy)) {
Occupancy$Ft[i] <- Occupancy$Ft[i - 1] + 0.3 * Occupancy$E[i - 1]
Occupancy$E[i] <- Occupancy[i, 2] - Occupancy$Ft[i]
}
View(Occupancy)
n <- nrow(Occupancy)
Forcast <- Occupancy$Ft[n] + 0.3 * Occupancy$E[n]
Forcast
model <- lm(Occupancy$OccupancyRate ~ Occupancy$Period)
summary(model)
34.94191 + 0.01510  * 167
nrow(Occupancy)
library(tidyverse)
names(Occupancy)
ES_SE <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
ES_SE
ES_SE
ES_SE <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
Occupancy <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
ES_MSE <- mean(Occupancy$sqErr)
ES_MSE
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
F167 <- 34.94191 + 0.01510  * 167
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
lr_MSE <- mean(Occupancy$sqErr)
lr_MSE
Occupancy <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/occupancyratestimeseries (1).csv")
Occupancy$Ft = 0
Occupancy$E = 0
head(Occupancy)
Occupancy$Ft[1] <- Occupancy[1, 2]
head(Occupancy)
#Ft = F(t - 1) + a * E(t - 1)
for (i in 2:nrow(Occupancy)) {
Occupancy$Ft[i] <- Occupancy$Ft[i - 1] + 0.3 * Occupancy$E[i - 1]
Occupancy$E[i] <- Occupancy[i, 2] - Occupancy$Ft[i]
}
n <- nrow(Occupancy)
Forcast <- Occupancy$Ft[n] + 0.3 * Occupancy$E[n]
Forcast
model <- lm(Occupancy$OccupancyRate ~ Occupancy$Period)
summary(model)
F167 <- 34.94191 + 0.01510  * 167
F167
Occupancy <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
ES_MSE <- mean(Occupancy$sqErr)
ES_MSE
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
lr_MSE <- mean(Occupancy$sqErr)
lr_MSE
View(occupancy)
View(Occupancy)
View(Occupancy2)
ES_MSE <- mean(Occupancy$sqErr)
ES_MSE
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
lr_MSE <- mean(Occupancy2$sqErr)
lr_MSE
names(Occupancy)
ggplot(Occupancy, aes(x = Period, y = OccupancyRate)) + geom_line()
sd(Occupancy$OccupancyRate)
Ïƒ <- sd(Occupancy$OccupancyRate)
mySD <- sd(Occupancy$OccupancyRate)
mySD
F167 + 1.96 * mySD
OccupanyRateNext <- F167 + 1.96 * mySD
OccupanyRateNext
nextData <- c(167, OccupanyRateNext)
Occupancy2 <- data.frame(rbind(Occupancy, nextData))
ggplot(Occupancy2, aes(Period, OccupancyRate)) + geom_line()
OccupanyRateNext
xt <- F167 + 1.96 * mySD
OccupanyRatext <- F167 + 1.96 * mySD
OccupanyRateNext
OccupanyRatext1 <- F167 + 1.96 * mySD
OccupanyRateNext2 <- F167 - 1.96 * mySD
OccupanyRateNext2
OccupanyRatext1
knitr::opts_chunk$set(echo = TRUE)
glass <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/glass.data.csv", header = FALSE, sep = ",")
names(glass) <- c("Id", "RI", "Na", "Mg", "Al", "Si", "K", "Ca", "Ba", "Fe", "glassType")
# Add column names to the dataset
str(glass)
# transform the glassType into factor.First we take a look at what types are there
unique(glass$glassType)
glass$glassType <- factor(glass$glassType,
labels = c("buildingFloat", "buildingNonFloat",
"vehicleFloat", "containers", "tableware", "headlamps"))
class(glass$glassType)
summary(glass[, 3:10])
NaData <- glass$Na
h <- hist(NaData, col = "red", xlab = "Na: Sodium", main="Histogram with Normal Curve")
xfit<-seq(min(NaData),max(NaData),length=40)
yfit<-dnorm(xfit,mean=mean(NaData),sd=sd(NaData))
yfit <- yfit*diff(h$mids[1:2])*length(NaData)
lines(xfit, yfit, col="blue", lwd=2)
#remove the first column and assign the data to glass2
glass2 <- glass[, -1]
#create a function called normalize
normalize <- function(x) {
return( (x - min(x)) / ( max(x) - min(x) ) )
}
#normalize the first 2 columns and save them to glass2
glassSub <- as.data.frame(lapply(glass2[, c(1:2)], normalize))
head(glassSub)
summary(glassSub)
glass2[, 1:2] <- glassSub
#create a function named normalizeZ
normalizeZ <- function(x){
return( (x - mean(x)) / sd(x) )
}
#normalize the remaining columns and save them to glass2
glassSub2 <- as.data.frame(lapply(glass2[, c(3:9)], normalizeZ))
head(glassSub2)
summary(glassSub2)
glass2[, 3:9] <- glassSub2
summary(glass2)
#Create a dataset in random selection order
set.seed(123)
gp <- runif(nrow(glass2))
glass2 <- glass2[order(gp), ]
head(glass2, 15)
str(glass2)
#Data partitioning
glass2Train <- glass2[1 : 107, ]
glass2Test <- glass2[108 : 214, ]
unknownGlass1 <- c(1.51621, 12.53, 3.48, 1.39, 73.39, 0.60, 8.55, 0.00, 0.05)
unknownGlass2 <- c(1.5098, 12.77, 1.85, 1.81, 72.69, 0.59, 10.01, 0.00, 0.01)
#A. transform the given data
#a. binding the new data into the original data
glass3 <- rbind(unknownGlass1, glass)
glass3 <- rbind(unknownGlass2, glass3)
glass3 <- glass3[, -1]
#transfrom the first 2 column using min-max normalization
glass3Sub <- as.data.frame(lapply(glass3[, c(1:2)], normalize))
head(glass3Sub)
summary(glass3Sub)
glass3[, 1:2] <- glass3Sub
#transform the left using Z score standarzation
#normalize the remaining columns and save them to glass2
glass3Sub2 <- as.data.frame(lapply(glass3[, c(3:9)], normalizeZ))
head(glass3Sub2)
summary(glassSub2)
glass3[, 3:9] <- glass3Sub2
summary(glass3)
#take out the 2 unknow cases from glass3
unknownGlass1Tran <- glass3[1, ]
unknownGlass2Tran <- glass3[2, ]
unknownGlass1Tran
unknownGlass2Tran
glass3 <- glass3[-c(1, 2), ]
#B. Predict the glass type for the unkonwn glasses
#for 2 single cases:
getDist <- function(p, q) {
dsq <- 0
for (i in 1 : length(p)) {
dsq <- dsq + (p[i] - q[i])^2
}
return(sqrt(dsq))
}
#For the first unknown glass:
#loop through each row in the glass3 data set
getDistN <- function(training, q) {
distance <- numeric(nrow(training))
q <- as.numeric(unknownGlass1Tran[c(1:9)])
for (i in 1 : nrow(training)) {
p <- training[i, c(1:9)]
distance[i] <- getDist(p, q)
}
return(distance)
}
n1 <- getDistN(glass3, unknownGlass1Tran)
#getting the k closest neighbors in for unknownGlass1Tran
findKClosest <- function(neighbors, k) {
neighborOrder <- order(neighbors)
return (neighborOrder[1 : k])
}
f <- findKClosest(n1, 10)
vote <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
vote(glass3$glassType[f])
# We know that the first unknown glass could be containers
#For the second unknown glass:
getDistN2 <- function(training, q) {
distance <- numeric(nrow(training))
q <- as.numeric(unknownGlass2Tran[c(1:9)])
for (i in 1 : nrow(training)) {
p <- training[i, c(1:9)]
distance[i] <- getDist(p, q)
}
return(distance)
}
n2 <- getDistN2(glass3, unknownGlass2Tran)
#getting the k closest neighbors in for unknownGlass2Tran
f2 <- findKClosest(n2, 10)
vote(glass3$glassType[f2])
# The second unknown glass could also be containers
library(class)
glass2TrainTarget <- glass2[1 : 107, 10]
glass2TestTarget <- glass2[108 : 214, 10]
d <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 14)
table(glass2TestTarget, d)
# when k = 5
d5 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 5)
table(glass2TestTarget, d5)
# accruacy5 = (24 + 23 + 3 + 11 + 1) / 107 = 57.94%
# when k = 6
d6 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 6)
table(glass2TestTarget, d6)
#accruacy6 = (26 + 21 + 1 + 4 + 10) / 107 = 57.94%
d7 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 7)
table(glass2TestTarget, d7)
#accuracy7 = (23 + 25 + 3 + 10) / 107 = 57.01%
d8 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 8)
table(glass2TestTarget, d8)
# accuracy8 = (26 + 25 + 3 + 10) / 107 = 59.81%
d9 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 9)
table(glass2TestTarget, d9)
#accuracy9 = (25 + 25 + 1 + 10)/107 = 57.01%
d10 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 10)
table(glass2TestTarget, d10)
#accuracy10 = (22 + 25 + 3 + 10) / 107 = 56.07%
d11 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 11)
table(glass2TestTarget, d11)
#accuracy11 = (23 + 28 + 2 + 10) / 107 = 58.87%
d12 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 12)
table(glass2TestTarget, d12)
#accuracy12 = (25 + 28 + 2 + 10)/107 = 60.75%
d13 <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 13)
table(glass2TestTarget, d13)
#accuracy13 = (27 + 26 + 1 + 10) / 107 = 59.81%, and from q9 we know accuracy14 = 60.75%
k <- c(5, 6, 7, 8, 9, 10, 11, 12, 13, 14)
accuracy <- c(0.5794,  0.5794, 0.5700, 0.5981, 0.5701, 0.5607, 0.5888, 0.6075, 0.5981, 0.6074766)
accuracyChange <- data.frame(cbind(k, accuracy))
library(ggplot2)
ggplot(accuracyChange, aes(x = k, y = accuracy)) + geom_line()
error <- c(0.4206, 0.4206, 0.4300, 0.40191, 0.4299, 0.4393, 0.4112, 0.3943, 0.4019, 0.3925)
errorChange <- data.frame(cbind(k, error))
ggplot(errorChange, aes(x = k, y = error)) + geom_line()
#when k = 12:
library("gmodels")
testPred <- knn(train = glass2Train[, -10], test = glass2Test[, -10], cl = glass2TrainTarget, k = 12)
CrossTable(x = glass2TestTarget, y = testPred, prop.chisq=FALSE)
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
str(homeprice)
# We know that there are 21613 cases, 21 features,
library(C5O)
install.packages(C5O)
install.packages("C5O")
data(churn)
data(churn)
?knn.predict
?knn()
accuracy14 <- (26 + 29 + 10) / 107
accuracy14
View(glass3)
knn(train = glass3[, -10], test = unknownGlass1Tran, cl = glass3$glassType, k = 14 )
unknownGlass1Tran
knn(train = glass3[, -10], test = unknownGlass1Tran[-10 ], cl = glass3$glassType, k = 14 )
knn(train = glass3[, -10], test = unknownGlass2Tran[-10 ], cl = glass3$glassType, k = 14 )
unknownType1 <- knn(train = glass3[, -10], test = unknownGlass1Tran[-10 ], cl = glass3$glassType, k = 14 )
unknownType2 <- knn(train = glass3[, -10], test = unknownGlass2Tran[-10 ], cl = glass3$glassType, k = 14 )
unknownType1
unknowType2
unknownType2
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
str(homeprice)
View(homeprice)
summary(homeprice)
summary(homeprice$price)
names(homeprice)
1100000 - 1
homePrice2 <- within(homePrice, {
price[price < 100000] <- "< 100000"
price[price >= 100000 & price < 600000 ] <- "100000-59999"
price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
price[price >= 1600000] <- ">1600000"
})
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
str(homeprice)
homePrice2 <- within(homePrice, {
price[price < 100000] <- "< 100000"
price[price >= 100000 & price < 600000 ] <- "100000-59999"
price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
price[price >= 1600000] <- ">1600000"
})
homePrice2 <- within(homeprice, {
price[price < 100000] <- "< 100000"
price[price >= 100000 & price < 600000 ] <- "100000-59999"
price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
price[price >= 1600000] <- ">1600000"
})
View(homePrice2)
homeprice2$price <- factor(homePrice2$price)
homePrice2$price <- factor(homePrice2$price)
str(homePrice2)
str(homePrice2$price)
levels(homePrice2)
homePrice2$price <- factor(homePrice2$price,
lables = c("< 100000", "100000-59999","600000-1099999", "1100000-1599999", ">1600000"))
?factor()
homePrice2$price <- factor(homePrice2$price,
levels = c("< 100000", "100000-59999","600000-1099999", "1100000-1599999", ">1600000"))
str(homePrice2$price)
str(homePrice2$price)
summary(homePrice2)
homePrice3 <- as.data.frame(lapply(homePrice2[, c(4 : 16, 18:21)], normalize))
head(homePrice3)
head(homePrice3)
str(homePrice3)
homePrice3 <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
head(homePrice3)
str(homePrice3)
summary(homePrice3)
set.seed(9850)
gp <- runif(nrow(homePrice3))
homePrice3 <- homePrice3[order(gp), ]
head(homePrice3, 15)
str(homePrice3)
str(homePrice)
str(homeprice)
str(homePrice3)
str(homePrice2)
homePrice3 <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
str(homePrice3)
homePriceSub <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
homePrice3 <- data.frame(cbind(homePrice2[, 2:3]), homePriceSub)
str(homePrice3)
set.seed(9850)
gp <- runif(nrow(homePrice3))
homePrice3 <- homePrice3[order(gp), ]
head(homePrice3, 15)
str(homePrice3)
21613 * 70%
21613 * 0.7
priceTrain <- homePrice3[1 : 15130, ] #70% of the data are set as training
priceTest <- homePrice3[15131 : 21613, ]
priceTrainTarget <- priceTrain$price
priceTestTarget <- priceTest$price
sqrt(21613)
sqrt(21613)
predTest <- knn(train = priceTrain, test = priceTest, cl = priceTrainTarget, k = 147)
View(priceTrain)
View(homePrice3)
str(priceTrain)
predTest <- knn(train = priceTrain[, -c(1:2)], test = priceTest[, -c(1:2)], cl = priceTrainTarget, k = 147)
head(priceTrain(3:20))
head(priceTrain[3:20])
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147)
anyNa(homePrice3)
anyNA(homePrice3)
anyNA(homePrice2)
homePrice2 <- na.omit(homePrice2)
str(homePrice2)
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
str(homeprice)
homePrice2 <- within(homeprice, {
price[price < 100000] <- "< 100000"
price[price >= 100000 & price < 600000 ] <- "100000-59999"
price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
price[price >= 1600000] <- ">1600000"
})
homePrice2$price <- factor(homePrice2$price,
levels = c("< 100000", "100000-59999","600000-1099999", "1100000-1599999", ">1600000"))
str(homePrice2$price)
summary(homePrice2)
anyNA(homePrice2)
homePrice2 <- na.omit(homePrice2)
str(homePrice2)
homePriceSub <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
homePrice3 <- data.frame(cbind(homePrice2[, 2:3]), homePriceSub) #exclude the id column
str(homePrice3)
set.seed(9850)
gp <- runif(nrow(homePrice3))
homePrice3 <- homePrice3[order(gp), ]
head(homePrice3, 15)
str(homePrice3)
priceTrain <- homePrice3[1 : 15130, ] #70% of the data are set as training
priceTest <- homePrice3[15131 : 21613, ]
priceTrainTarget <- priceTrain$price
priceTestTarget <- priceTest$price
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147)
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147, na.omit = TRUE)
anyNA(priceTrain)
str(priceTrain[3:20])
sqrt(nrow(homePrice3))
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147)
str(test = priceTest[3:20])
str(priceTest[3:20])
homeprice <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/data analytics/kc_house_data.csv")
summary(homeprice$price)
homePrice2 <- within(homeprice, {
price[price < 100000] <- "< 100000"
price[price >= 100000 & price < 600000 ] <- "100000-59999"
price[price >= 600000 & price < 1100000 ] <- "600000-1099999"
price[price >= 1100000 & price < 1600000 ] <- "1100000-1599999"
price[price >= 1600000] <- ">1600000"
})
homePrice2$price <- factor(homePrice2$price,
levels = c("< 100000", "100000-59999","600000-1099999", "1100000-1599999", ">1600000"))
str(homePrice2$price)
summary(homePrice2)
anyNA(homePrice2)
homePrice2 <- na.omit(homePrice2)
str(homePrice2)
homePriceSub <- as.data.frame(lapply(homePrice2[, c(4 : 21)], normalize))
homePrice3 <- data.frame(cbind(homePrice2[, 2:3]), homePriceSub) #exclude the id column
str(homePrice3)
set.seed(9850)
gp <- runif(nrow(homePrice3))
homePrice3 <- homePrice3[order(gp), ]
head(homePrice3, 15)
str(homePrice3)
nrow(homePrice3)
21349*0.7
priceTrain <- homePrice3[1 : 14944, ] #70% of the data are set as training
priceTest <- homePrice3[14945 : 21349, ]
priceTrainTarget <- priceTrain$price
priceTestTarget <- priceTest$price
sqrt(nrow(homePrice3))
predTest <- knn(train = priceTrain[3:20], test = priceTest[3:20], cl = priceTrainTarget, k = 147)
table(priceTestTarget, predTest)
10 + 4784 + 139 + 779 + 4 + 105 + 153 + 431
nrow(priceTest)
(4784 + 431) / 6405
Act_Test <- priceTrain[3:20]
pred_Test <- test = priceTest[3:20]
pred_Test <- priceTest[3:20]
CrossTable(x = Act_Test , y = pred_Test, prop.chisq=FALSE)
nrow(predTest)
AccuracyRate <-  (4784 + 431) / 6405
AccuracyRate
Occupancy <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/occupancyratestimeseries (1).csv")
ggplot(Occupancy, aes(x = Period, y = OccupancyRate)) + geom_line()
Occupancy$Ft = 0
Occupancy$E = 0
head(Occupancy)
Occupancy$Ft[1] <- Occupancy[1, 2]
head(Occupancy)
Occupancy <- read.csv("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/week4/practicum/occupancyratestimeseries (1).csv")
ggplot(Occupancy, aes(x = Period, y = OccupancyRate)) + geom_line()
Occupancy$Ft = 0
Occupancy$E = 0
head(Occupancy)
Occupancy$Ft[1] <- Occupancy[1, 2]
head(Occupancy)
for (i in 2:nrow(Occupancy)) {
Occupancy$Ft[i] <- Occupancy$Ft[i - 1] + 0.3 * Occupancy$E[i - 1]
Occupancy$E[i] <- Occupancy[i, 2] - Occupancy$Ft[i]
}
n <- nrow(Occupancy)
Forcast <- Occupancy$Ft[n] + 0.3 * Occupancy$E[n]
Forcast
nrow(Occupancy)
model <- lm(Occupancy$OccupancyRate ~ Occupancy$Period)
summary(model)
F167 <- 34.94191 + 0.01510  * 167
F167
library(tidyverse)
Occupancy <- mutate(Occupancy, sqErr = ( OccupancyRate - Forcast)^2)
ES_MSE <- mean(Occupancy$sqErr)
ES_MSE
Occupancy2 <- mutate(Occupancy, sqErr = ( OccupancyRate - F167)^2)
lr_MSE <- mean(Occupancy2$sqErr)
lr_MSE
mySD <- sd(Occupancy$OccupancyRate)
mySD
#next time period with a 95% prediction interval
OccupanyRateNe
install.packages("tidyverse")
