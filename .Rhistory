data("LakeHuron")
head(LakeHuron)
year <- 1875 : 1972
level <- LakeHuron
df <- data.frame(year, level)
head(df)
tail(df)
library(ggplot2)
ggplot(df, aes(year, level)) + geom_line()
model <- lm(df$level ~ df$year)
summar(model)
summary(model)
print(model)
F.t <- 25.5549  +  (-0.0242) * 1973
F.t
F.t <- 625.5549  +  (-0.0242) * 1973
F.t
df$absErr <- 0
df$F <- 0
df$E[i] <- abs(df$[i, 2] - df$F[i])
for (i in nrow(df)) {
df$F[i] <- -0.024 * df$year[i] + 625.5549
df$E[i] <- abs(df$[i, 2] - df$F[i])
}
df$E[i] <- abs(df[i, 2] - df$F[i])
for (i in nrow(df)) {
df$F[i] <- -0.024 * df$year[i] + 625.5549
df$absErr[i] <- abs(df[i, 2] - df$F[i])
}
head(df)
df$F <- 0
df$absErr <- 0
for (i in nrow(df)) {
df$F[i] <- -0.024 * df$year[i] + 625.5549
df$absErr[i] <- abs(df[i, 2] - df$F[i])
}
head(df)
for (i in 1:nrow(df)) {
df$F[i] <- -0.024 * df$year[i] + 625.5549
df$absErr[i] <- abs(df[i, 2] - df$F[i])
}
head(df)
mean(df$absErr)
head(df)
data("LakeHuron")
head(LakeHuron)
year <- 1875 : 1972
df <- data.frame(year, LakeHuron)
#Moving Average
#4-year Moving Average
n <- nrow(df)
tail(df)
last4 <- df[n : (n - 3), 2]
mean(last4)
#Weighted Moving Average
#Must define weights
#Choose 3, 2, 1, 1
last4
w <- c(3, 2, 1, 1)
tail(df)
sw <- w * last4
F <- sum(sw)/sum(w)
#Exponential Smoothing
#alpha = 0.3
df$Ft = 0
df$E = 0
head(df)
df$Ft[1] <- df[1, 2]
head(df)
#Ft = F(t - 1) + a * E(t - 1)
df$Ft[2] <- df$Ft[1] + 0.3 * df$E[1]
head(df)
df$E[2] <- df[2, 2] - df$Ft[2]
head(df)
for (i in 2:nrow(df)) {
df$Ft[i] <- df$Ft[i - 1] + 0.3 * df$E[i - 1]
df$E[i] <- df[i, 2] - df$Ft[i]
}
head(df)
tail(df)
n <- nrow(df)
Forcast <- df$Ft[n] + 0.3 * df$E[n]
Forcast
mean(df$E)
clear()
knitr::opts_chunk$set(echo = TRUE)
data(USArrest)
data("USArrest")
data("USAarrest")
str(USArrests)
mean(USArrests$Assault)
sd(USArrests$Assault)
average <- mean(USArrests$Assault)
std <- sd(USArrests$Assault)
z <- (USArrests$Assault - average) / std
z
outlier <- USArrests$Assault[which(USArrests$Assault > 1.5 * std + average)]
outlier
View(USArrests)
USArrests[outlier]
outlier
USArrests[c(335, 300, 337)]
USArrests[c(335, 300, 337),]
USArrests[which(outlier)]
USArrests[335,]
outlier <- USArrests[which(USArrests$Assault > 1.5 * std + average)]
outlier
str(USArrests)
library(tidyverse)
USArrests2 <- mutate(USArrests, id = row_number())
View(USArrests2)
Summary(USArrests)
summary(USArrests)
attributes(USArrests)[1]
attributes(USArrests)[3]
row.names(USArrests)[c(outlier)]
row.names(USArrests)[USArrests$Assault = outlier]
row.names(USArrests$Assault = outlier)
?which()
stateNames <- row.names(USArrests)
average <- mean(USArrests$Assault)
std <- sd(USArrests$Assault)
outlier <- USArrests$Assault[which(USArrests$Assault > 1.5 * std + average)]
outlier
library(tidyverse)
mutate(USArrests, stateNames = row.names(USArrests) )
average <- mean(USArrests2$Assault)
USArrests2 <- mutate(USArrests, stateNames = row.names(USArrests) )
average <- mean(USArrests2$Assault)
std <- sd(USArrests2$Assault)
outlier <- USArrests2$Assault[which(USArrests2$Assault > 1.5 * std + average)]
names(USArrests2)
filter(USArrests2, Assault > 1.5 * std + average)
outliers$stateNames
outliers <- filter(USArrests2, Assault > 1.5 * std + average)
outliers$stateNames
?cor()
View(USArrests2)
cor(USArrests2, use = all.obs, method = pearson)
cor(USArrests2, method = pearson)
cor(USArrests2, method = "pearson)
cor(USArrests2, use = "all.obs", method = "pearson)
cor(USArrests2, use = "all.obs", method = "pearson")
cor(USArrests2, x = murder, y = assault, use = "all.obs", method = "pearson")
cor(USArrests2, x = USArrests2$murder, y = USArrests2$assault, use = "all.obs", method = "pearson")
cor(x = USArrests2$murder, y = USArrests2$assault, use = "all.obs", method = "pearson")
cor(USArrests2$murder, USArrests2$assault)
?cor.test()
cor.test(USArrests2$murder, USArrests2$assault)
names(USArrests)
cor.test(USArrests2, Murder, Assault)
cor.test(USArrests2$Murder, USArrests2$Assault, method = "spearman")
library(readxl)
read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
phone <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
View(phone)
phoneUse <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
View(phoneUse)
n <- nrow(phoneUse)
last3 <- phoneUse(n : (n - 2), 2)
phoneUse <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
last3 <- phoneUse(n : (n - 2), 2)
n <- nrow(phoneUse)
last3 <- phoneUse[n : (n - 2), 2]
last3
View(last3)
mean(last3)
mean(last3)
mean(last3, na.rm = TRUE)
last3
mean(last3$Subscribers)
w <- c(4, 1, 1)
sw <- last3 * w
sw
F <- sum(sw$Subscribers) / sum(w)
F
phoneUse$F = 0
phoneUse$E = 0
View(phoneUse)
phoneUse$Ft = 0
library(tidyverse)
str(USArrests)
USArrests2 <- mutate(USArrests, stateNames = row.names(USArrests) )
#Find outliers in assaults
average <- mean(USArrests2$Assault)
std <- sd(USArrests2$Assault)
outliers <- filter(USArrests2, Assault > 1.5 * std + average)
outliers$stateNames
cor.test(USArrests2$Murder, USArrests2$Assault, method = "spearman")
library(readxl)
phoneUse <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
#Use a 3-year moving average to predict the next month
n <- nrow(phoneUse)
last3 <- phoneUse[n : (n - 2), 2]
mean(last3$Subscribers)
# 3-year weighted moving average
w <- c(4, 1, 1)
sw <- last3 * w
F <- sum(sw$Subscribers) / sum(w)
F
#exponential smoothing
phoneUse$Ft = 0
phoneUse$E = 0
View(phoneUse)
df$Ft = 0
data("LakeHuron")
head(LakeHuron)
year <- 1875 : 1972
df <- data.frame(year, LakeHuron)
df$Ft = 0
df$E = 0
df$Ft[1] <- df[1, 2]
View(df)
phoneUse$Ft[1] <- phoneUse$Subscribers[1]
phoneUse$E[i] = phoneUse$Subscribers[i] - phoneUse$Ft[i]
for (i in 2 : nrow(phoneUse)) {
phoneUse$Subscribers[i] = phoneUse$Subscribers[i - 1] + 0.2 * phoneUse$E[i - 1]
phoneUse$E[i] = phoneUse$Subscribers[i] - phoneUse$Ft[i]
}
View(phoneUse)
phoneUse$Ft[2] <- phoneUse$Ft[1] + 0.2 * phoneUse$E[1]
for (i in 2 : nrow(phoneUse)) {
phoneUse$Subscribers[i] = phoneUse$Subscribers[i - 1] + 0.2 * phoneUse$E[i - 1]
phoneUse$E[i] = phoneUse$Subscribers[i] - phoneUse$Ft[i]
}
View(phoneUse)
library(readxl)
phoneUse <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
#Use a 3-year moving average to predict the next month
n <- nrow(phoneUse)
last3 <- phoneUse[n : (n - 2), 2]
mean(last3$Subscribers)
# 3-year weighted moving average
w <- c(4, 1, 1)
sw <- last3 * w
F <- sum(sw$Subscribers) / sum(w)
F
#exponential smoothing
phoneUse$Ft = 0
phoneUse$E = 0
phoneUse$Ft[1] <- phoneUse$Subscribers[1]
for (i in 2 : nrow(phoneUse)) {
phoneUse$Subscribers[i] = phoneUse$Subscribers[i - 1] + 0.2 * phoneUse$E[i - 1]
phoneUse$E[i] = phoneUse$Subscribers[i] - phoneUse$Ft[i]
}
View(phoneUse)
phoneUse <- read_excel("/Users/sunmengyue/Dropbox/2. Northeastern Unviersity/Fall2018/DA 5030 DataMining and Machine Learning/Week3/Brazildata.xlsx")
View(phoneUse)
phoneUse2 <- mutate(phoneUse, Ft = 0, E = 0)
View(phoneUse2)
phoneUse2$Ft[1] <- phoneUse$Subscribers[1]
phoneUse2$Ft[1] <- phoneUse2$Subscribers[1]
View(phoneUse2)
for (i in 2 : nrow(phoneUse)) {
phoneUse2$Subscribers[i] = phoneUse2$Subscribers[i - 1] + 0.2 * phoneUse2$E[i - 1]
phoneUse2$E[i] = phoneUse2$Subscribers[i] - phoneUse2$Ft[i]
}
View(phoneUse2)
phoneUse2 <- mutate(phoneUse, Ft = 0, E = 0)
phoneUse2$Ft[1] <- phoneUse2$Subscribers[1]
View(phoneUse2)
for (i in 2 : nrow(phoneUse)) {
phoneUse2$Ft[i] = phoneUse2$Subscribers[i - 1] + 0.2 * phoneUse2$E[i - 1]
phoneUse2$E[i] = phoneUse2$Subscribers[i] - phoneUse2$Ft[i]
}
View(phoneUse2)
phoneUse2 <- mutate(phoneUse, Ft = 0, E = 0)
phoneUse2$Ft[1] <- phoneUse2$Subscribers[1]
View(phoneUse2)
for (i in 2 : nrow(phoneUse)) {
phoneUse2$Ft[i] = phoneUse2$Ft[i - 1] + 0.2 * phoneUse2$E[i - 1]
phoneUse2$E[i] = phoneUse2$Subscribers[i] - phoneUse2$Ft[i]
}
View(phoneUse2)
subscriber12 <- phoneUse2$Ft[11] + 0.2 * phoneUse2$E[11]
subscriber12
ggplot(phoneUse, aes(x = Year, y = Subscribers)) + geom_line()
model <- lm(phoneUse$Subscribers ~ phoneUse$Year)
summary(model)
data("LakeHuron")
head(LakeHuron)
year <- 1875 : 1972
level <- LakeHuron
df <- data.frame(year, level)
model2 <- lm(df$level ~ df$year)
summary(model2)
summary(model)
summary(model)
subscriberYear12 <- -15710760 + 18276748 * 12
subscriberYear12
View(pohoneUse)
View(phoneUse)
View(last3)
last3
mean(last3$Subscribers)
phoneUseMA_MSE <- mutate(phoneUse, sqErr = (Subscribers - mean(last3$Subscribers))^2)
phoneUseMA_MSE
9^2
phoneUseMA_SE <- mutate(phoneUse, sqErr = (Subscribers - mean(last3$Subscribers))^2)
phoneUseMA_MSE <-mean(phoneUseMA_SE$sqErr)
phoneUseMA_MSE
phoneUseWMA_SE <- mutate(phoneUse, sqErr = (Subscribers - F)^2)
phoneUseWMA_SE
phoneUseWMA_MSE <- mean(phoneUseWMA_SE$sqErr)
phoneUseWMA_MSE
phoneUseES_SE <- mutate(phoneUse, sqErr = (Subscribers - subscriber12)^2)
phoneUseES_MSE <- mean(phoneUseES_SE$sqErr)
phoneUseES_MSE
phoneUselr_SE <- mutate(phoneUse, sqErr = (Subscribers - subscriberYear12)^2)
phoneUselr_MSE <- mean(phoneUselr_SE$sqErr)
phoneUselr_MSE
weightSum <- 3 + 2 + 1
weightSum <- 3 + 2 + 1
weightedAve <- (3 * subscriberYear12 + 2*subscriber12 + F)/weightSum
weightedAve
#subscriberYear12 is the subscribers predicted in the 12th year using linear regression,
#subscriber12 is the subscribers predicted in the 12th year using exponential smoothing,
#F is the 3 year weighted moving average
method
